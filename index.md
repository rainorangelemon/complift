---
layout: default
name: "Improving Compositional Generation with Diffusion Models Using Lift Scores"
title:  "Improving Compositional Generation with Diffusion Models Using Lift Scores"
description: a compositional criteria for rejection and resampling of samples generated by diffusion models
date:   2020-05-21 15:38:11 -0800
usemathjax: true
---

Diffusion models have revolutionized generative modeling, particularly in producing high-quality images. Yet, when faced with complex prompts involving multiple objects or conditions, they often stumble: generated images might satisfy only part of a prompt or contain inconsistencies.

In our ICML 2025 paper, we introduce **CompLift**â€”a lightweight, training-free rejection criterion using **lift scores**â€”to address this issue.

# Table of Contents:

1. [Sometimes, Compositional Prompts Break Diffusion Models](#-sometimes-compositional-prompts-break-diffusion-models)
2. [A Toy 2D Example](#-a-toy-2d-example)
3. [What is CompLift?](#-what-is-complift)
    1. [Lift Scores, Explained](#-lift-scores-explained)
    2. [Compositional Logic via Lift](#-compositional-logic-via-lift)
    3. [Efficient Implementation](#-efficient-implementation)
4. [Results](#-results)
5. [Lift in the Latent Space](#-lift-in-the-latent-space)

## ðŸ¤” Sometimes, Compositional Prompts Break Diffusion Models

Compositional prompts require satisfying multiple conditions simultaneously. Some diffusion models, e.g., Stable Diffusion, trained on rich datasets tend to focus on the objects mentioned with an earlier order in the prompt. As a result, given a prompt like:

> "a black car and a white clock"

The model might tend to generate a black car, and ignore the white clock. See the example below - here we have 100 samples generated by [Stable Diffusion XL](https://arxiv.org/abs/2307.01952). The 62 blue-bordered samples indicate that they satisfy the constraint to include a white clock, while the 38 orange-bordered samples do not include a white clock.

<style>
.grid-container {
  display: grid;
  grid-template-columns: repeat(10, 1fr);
  gap: 5px;
  max-width: 800px;
  margin: 20px auto;
  position: relative;
}

.grid-item {
  aspect-ratio: 1;
  background-color: #f0f0f0;
  border: 2px solid #ddd;
  border-radius: 4px;
  transition: all 0.3s ease;
  position: relative;
  background-size: cover;
  background-position: center;
  cursor: pointer;
}

{% assign labels = "0,1,0,0,1,0,0,1,0,1,1,1,1,1,1,1,1,0,0,0,1,0,1,1,0,0,0,1,1,1,0,1,1,0,1,1,1,0,0,1,1,0,1,1,1,0,1,0,1,0,1,0,1,0,0,1,1,0,0,1,0,1,1,0,1,1,1,1,1,1,0,1,1,0,1,1,1,1,1,0,1,0,0,1,1,1,1,1,1,1,1,0,0,0,1,0,0,1,1,1" | split: "," %}

{% for i in (0..99) %}
{% assign label = labels[i] %}
{% if label == "1" %}
.grid-item:nth-child({{ i | plus: 1 }}) {
  border-color: #2196F3;
}
{% else %}
.grid-item:nth-child({{ i | plus: 1 }}) {
  border-color: #FF9800;
}
{% endif %}
{% endfor %}

.grid-item:hover {
  transform: scale(4);
  z-index: 2;
  box-shadow: 0 4px 15px rgba(0,0,0,0.2);
  border-radius: 8px;
  border-width: 3px;
}

/* Adjust transform origin based on position */
.grid-item:nth-child(10n) {
  transform-origin: left center;
}
.grid-item:nth-child(10n+1) {
  transform-origin: right center;
}
.grid-item:nth-child(-n+10) {
  transform-origin: center bottom;
}
.grid-item:nth-child(n+91) {
  transform-origin: center top;
}

/* Generate background-image rules for all 100 items */
{% for i in (0..99) %}
.grid-item:nth-child({{ i | plus: 1 }}) {
  background-image: url('{{ site.baseurl }}/images/{{ i }}.jpg');
}
{% endfor %}
</style>

<div class="grid-container">
  {% for i in (0..99) %}
    {% assign label = labels[i] %}
    <div class="grid-item" data-label="{{ label }}"></div>
  {% endfor %}
</div>

Some previous works, e.g., [Attend & Excite](https://arxiv.org/abs/2301.13826), hypothesize that this happens because the model is biased towards some parts of the prompt, while ignoring others.

Our goal is to design a **rejection criterion** that can detect whether a generated sample satisfies each component of a compositional prompt, and reject it if it does not.

## ðŸš€ What is CompLift?

**CompLift** is a plug-and-play resampling technique that checks if a generated sample truly satisfies a promptâ€”**without retraining or using any extra models**. It leverages a classic statistical idea: **lift scores**.

### ðŸ” Lift Scores, Explained

Lift measures how much a condition $$c$$ influences the probability of generating a sample $$x$$. Formally:

$$
\begin{equation}
\text{lift}(x|c) = \log\frac{p(x|c)}{p(x)} \tag{1}
\label{eqn:lift}
\end{equation}
$$

In practice, we show that we can approximate Eq. \eqref{eqn:lift} using the internal denoising predictions of the diffusion model itself. Similar techniques can be found in [Diffusion Classifier](https://diffusion-classifier.github.io/).

$$
\begin{equation}
\text{lift}(x|c) \approx \mathbb{E}_{t,\epsilon}\{||\epsilon-\epsilon_\theta(x_t, \varnothing)||^2-||\epsilon-\epsilon_\theta(x_t, c)||^2\} \tag{2}
\label{eqn:lift-approx}
\end{equation}
$$

Note:
- $$\epsilon_\theta$$ is the diffusion model
- $$t$$ is randomly sampled diffusion steps
- $$\epsilon \sim \mathcal{N}(0, I)$$ is the randomly sampled noise
- $$x_t$$ is the sample at step $$t$$, which is a noisy version of $$x_0$$

Intuitively, Eq. \eqref{eqn:lift-approx} means:

> If a sample aligns with the condition, the model should be **better at denoising it** when given that condition.

This allows us to check conditions *after* generation, and reject samples that don't satisfy them.

## ðŸ§  Compositional Logic via Lift

CompLift handles logical combinations of conditions:

- **AND (Product)**: Accept only if all subconditions have positive lift.
- **OR (Mixture)**: Accept if *any* subcondition has positive lift.
- **NOT (Negation)**: Reject if a subcondition is satisfied.

This compositional approach lets us flexibly combine prompts into logical structuresâ€”just like symbolic logic!

## âš™ï¸ Efficient Implementation

We propose two versions:

- **Naive CompLift**: Uses multiple sampling trials and computes lift via Monte Carlo.
- **Cached CompLift**: Reuses model outputs during sampling for **zero extra compute** in many settings.

## ðŸ§ª Results

We evaluate CompLift on:

- ðŸŽ¨ 2D synthetic tasks
- ðŸ§± CLEVR object positioning
- ðŸ–¼ Text-to-image generation (SD 1.4/2.1/XL)

Across the board, CompLift significantly improves prompt alignment without harming quality.

| Task           | Metric                | Baseline | +CompLift |
|----------------|------------------------|----------|-----------|
| 2D Product     | Accuracy               | 74.3%    | **94.8%** |
| CLEVR (5 objs) | All-Cond Satisfaction  | 49.2%    | **76.4%** |
| SD 2.1         | CLIP alignment (avg.)  | 0.287    | **0.345** |

## ðŸ”¬ Lift in the Latent Space

To handle fine-grained image prompts, we compute lift *per pixel* in the latent space, allowing us to detect whether each object is truly present. This even helps in understanding *which* part of the image aligns with each prompt component.

## ðŸ§° Get Started

Want to try it out?

```bash
git clone https://github.com/rainorangelemon/complift
cd complift
python run_lift.py --prompt "a black car and a white clock"
```

## ðŸ§© Final Thoughts

CompLift shows how diffusion models can be made **compositional**â€”by introspecting their own denoising behavior. It's simple, elegant, and practical.

While we've focused on image generation, the principles behind lift scores may apply to **video, music, or even language generation** in the future.

## ðŸ“„ Paper

> Yu, C., & Gao, S. (2025). *Improving Compositional Generation with Diffusion Models Using Lift Scores*. ICML 2025. [[GitHub](https://github.com/rainorangelemon/complift)]